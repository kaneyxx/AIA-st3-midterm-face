{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential,Model, load_model\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, Activation, \n",
    "                                     Flatten, BatchNormalization, ZeroPadding2D,\n",
    "                                     MaxPooling2D,Softmax, Convolution2D,)\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check GPU\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移除.ipynb_checkpoints資料夾, 避免讀取圖片時發生錯誤\n",
    "import shutil\n",
    "\n",
    "nowpath = os.getcwd()\n",
    "try:   \n",
    "    shutil.rmtree(nowpath +'/face_cnn_train/akane/.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "try:   \n",
    "    shutil.rmtree(nowpath +'/face_cnn_train/neru/.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "try:   \n",
    "    shutil.rmtree(nowpath +'/face_cnn_test/.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "try:   \n",
    "    shutil.rmtree(nowpath +'/face_cnn_train/rika/.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "try:   \n",
    "    shutil.rmtree(nowpath +'/face_cnn_train/risa/.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "try:   \n",
    "    shutil.rmtree(nowpath +'/face_cnn_train/yui/.ipynb_checkpoints')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./face_cnn_train\"\n",
    "\n",
    "x_data_list = []\n",
    "y_data_list = []\n",
    "for roots, dirs, files in os.walk(data_path):\n",
    "    if dirs == []:\n",
    "        for each in files:\n",
    "            if each.find('check') == -1:\n",
    "                x_data_list.append(os.path.join(roots, each))\n",
    "                y_data_list.append(roots.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./face_cnn_test\"\n",
    "names=[]\n",
    "test_list = []\n",
    "for roots, dirs, files in os.walk(data_path):\n",
    "        for each in files:\n",
    "            if each.find('check') == -1:\n",
    "                names.append(each.split(\".\")[0])\n",
    "                test_list.append(os.path.join(roots, each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(data_list):\n",
    "    data_img = []\n",
    "    for each in tqdm(data_list):\n",
    "        img = cv2.imread(each, 1)\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        data_img.append(img)\n",
    "\n",
    "    return np.array(data_img)  #.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = load_img(x_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_list = pd.DataFrame(y_data_list, columns=['label'])\n",
    "uniques = y_data_list['label'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = pd.read_csv(\"./classmap.csv\",header=None, index_col=0)\n",
    "class_map = class_map.to_dict()[1]\n",
    "\n",
    "y_data = y_data_list['label'].map(class_map).values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprcoess\n",
    "x_data = preprocess_input(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "y_data = keras.utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training/validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_data, y_data,\n",
    "                                                                                                       test_size=0.1,\n",
    "                                                                                                       random_state=666,\n",
    "                                                                                                       stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_list(models, model_name):\n",
    "    model_dir = './Model/{}-logs'.format(model_name)\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    logfiles = model_dir + '/{}-{}'.format('basic_model',\n",
    "                                           models.__class__.__name__)\n",
    "    model_cbk = keras.callbacks.TensorBoard(log_dir=logfiles,\n",
    "                                            histogram_freq=1)\n",
    "\n",
    "    modelfiles = model_dir + '/{}-best-model.h5'.format('basic_model')\n",
    "    model_mckp = keras.callbacks.ModelCheckpoint(modelfiles,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 save_best_only=True)\n",
    "\n",
    "    return [model_cbk, model_mckp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define VGG_FACE_MODEL architecture\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(ZeroPadding2D((1,1)))\t\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Load VGG Face model weights\n",
    "model.load_weights('./vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove last Softmax layer and get model upto last flatten layer\n",
    "vgg_face=Model(inputs=model.layers[0].input,outputs=model.layers[-2].output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model=Sequential()\n",
    "classifier_model.add(vgg_face)\n",
    "classifier_model.add(Dense(units=64,kernel_initializer='he_uniform'))\n",
    "classifier_model.add(BatchNormalization())\n",
    "classifier_model.add(Activation('relu'))\n",
    "classifier_model.add(Dropout(0.2))\n",
    "classifier_model.add(Dense(units=32,kernel_initializer='he_uniform'))\n",
    "classifier_model.add(BatchNormalization())\n",
    "classifier_model.add(Activation('relu'))\n",
    "classifier_model.add(Dropout(0.2))\n",
    "classifier_model.add(Dense(units=16,kernel_initializer='he_uniform'))\n",
    "classifier_model.add(BatchNormalization())\n",
    "classifier_model.add(Activation('relu'))\n",
    "classifier_model.add(Dropout(0.2))\n",
    "classifier_model.add(Dense(units=5,kernel_initializer='he_uniform'))\n",
    "classifier_model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                                                    optimizer=keras.optimizers.Adam(lr=5e-5, decay = 1e-8),\n",
    "                                                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"凍結前可調整權重的層數：\", len(classifier_model.trainable_weights))\n",
    "\n",
    "vgg_face.trainable = False\n",
    "\n",
    "print(\"凍結後可調整權重的層數：\", len(classifier_model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_backs_face = call_list(classifier_model, \"vgg_face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epo = 30\n",
    "num_step = x_train.shape[0] // batch_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#                              width_shift_range=0.1,\n",
    "#                              height_shift_range=0.1,\n",
    "#                              horizontal_flip=True,\n",
    "#                              vertical_flip=False,\n",
    "#                              fill_mode='nearest'\n",
    "#                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_face = classifier_model.fit(x_train, y_train,\n",
    "                                                                      batch_size=batch_size,\n",
    "                                                                      epochs=epo,\n",
    "                                                                      validation_data=(x_valid, y_valid),\n",
    "                                                                      callbacks=call_backs_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_face = load_model('./Model/vgg_face-logs/basic_model-best-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_img(test_list)\n",
    "test_data = preprocess_input(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_face.predict(test_data)\n",
    "predictions = np.argmax(y_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission = pd.DataFrame({'Id':names, 'class': predictions})\n",
    "test_submission.to_csv('./try.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final result  \n",
    "**Public : 0.96183**  \n",
    "**Private: 0.88599**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
