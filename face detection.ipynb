{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlib.DLIB_USE_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移除.ipynb_checkpoints資料夾, 避免讀取圖片時發生錯誤\n",
    "import shutil\n",
    "\n",
    "nowpath = os.getcwd()\n",
    "try:   \n",
    "    shutil.rmtree(nowpath +'/traing_set/akane/.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "try:   \n",
    "    shutil.rmtree(nowpath +'/traing_set/neru/.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "try:   \n",
    "    shutil.rmtree(nowpath +'/testing_set/.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "try:   \n",
    "    shutil.rmtree(nowpath +'/traing_set/rika/.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "try:   \n",
    "    shutil.rmtree(nowpath +'/traing_set/risa/.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "try:   \n",
    "    shutil.rmtree(nowpath +'/traing_set/yui/.ipynb_checkpoints')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./training_set\"\n",
    "\n",
    "x_data_list = []\n",
    "y_data_list = []\n",
    "for roots, dirs, files in os.walk(data_path):\n",
    "    if dirs == []:\n",
    "        for each in files:\n",
    "            if each.find('check') == -1:\n",
    "                x_data_list.append(os.path.join(roots, each))\n",
    "                y_data_list.append(roots.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./testing_set\"\n",
    "names=[]\n",
    "test_list = []\n",
    "for roots, dirs, files in os.walk(data_path):\n",
    "        for each in files:\n",
    "            if each.find('check') == -1:\n",
    "                names.append(each.split(\".\")[0])\n",
    "                test_list.append(os.path.join(roots, each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('/home/kaneyxx/miniconda3/envs/tf2/lib/python3.7/site-packages/cv2/data/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_train_cv2(filename):\n",
    "    img = cv2.imread(filename)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray,\n",
    "                                          scaleFactor=1.1,\n",
    "                                          minNeighbors=3,)\n",
    "    count = 0\n",
    "    for (x,y,w,h) in faces:\n",
    "#         img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "        f = cv2.resize(img[y:y+h+30, x:x+w+30], (200, 200))\n",
    "        sets1 = filename.split(\"/\")\n",
    "        sets2 = filename.split(\"/\")[3].split(\".\")\n",
    "        name = \"./face_cv2_train/\" + sets1[2] + \"/\" + sets2[0] + \"_\" + str(count) + \".png\"\n",
    "        cv2.imwrite(name, f)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in x_data_list:\n",
    "    detect_train_cv2(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_test_cv2(filename):\n",
    "    img = cv2.imread(filename)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray,\n",
    "                                          scaleFactor=1.1,\n",
    "                                          minNeighbors=3,)\n",
    "    if len(faces) > 0:\n",
    "        count = 0\n",
    "        for (x,y,w,h) in faces:\n",
    "            f = cv2.resize(img[y:y+h+30, x:x+w+30], (200, 200))\n",
    "            sets = filename.split(\"/\")[2].split(\".\")\n",
    "            name = \"./face_cv2_test/\" + sets[0] + \"_\" + str(count) + \".png\"\n",
    "            cv2.imwrite(name, f)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in test_list:\n",
    "    detect_test_cv2(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"./shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = FaceAligner(predictor, desiredFaceWidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_train(path):\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray, 1)\n",
    "    sets1 = path.split(\"/\")\n",
    "    sets2 = path.split(\"/\")[3].split(\".\")\n",
    "    if len(faces) > 0:\n",
    "        count = 1\n",
    "        for face in faces:\n",
    "            try:\n",
    "                (x, y, w, h) = rect_to_bb(face)\n",
    "                faceOrig = imutils.resize(img[y : y+h, x : x+w], width=200)\n",
    "                faceAligned = fa.align(img, gray, face)\n",
    "                orig_name = \"./face_dlib_train/\" + sets1[2] + \"/\" + sets2[0] + \"_orig_\" + str(count) + \".\" + sets2[1]\n",
    "                cv2.imwrite(orig_name, faceOrig)\n",
    "                aligned_name = \"./face_dlib_train/\" + sets1[2] + \"/\" + sets2[0] + \"_align_\" + str(count) + \".\" + sets2[1]\n",
    "                cv2.imwrite(aligned_name, faceAligned)\n",
    "                count += 1\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x_data_list:\n",
    "    detect_face_train(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_test(path):\n",
    "    count = 1\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray, 1)\n",
    "    sets = path.split(\"/\")[2].split(\".\")\n",
    "    for face in faces:\n",
    "        try:\n",
    "            (x, y, w, h) = rect_to_bb(face)\n",
    "            faceOrig = imutils.resize(img[y : y+h, x : x+w], width=200)\n",
    "            faceAligned = fa.align(img, gray, face)\n",
    "            orig_name = \"./face_dlib_test/origin/\" + sets[0] + \"_orig_\" + str(count) + \".\" +sets[1]\n",
    "            cv2.imwrite(orig_name, faceOrig)\n",
    "            aligned_name = \"./face_dlib_test/aligned/\" + sets[0] + \"_align_\" + str(count) + \".\" +sets[1]\n",
    "            cv2.imwrite(aligned_name, faceAligned)\n",
    "            count += 1\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    detect_face_test(i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!wget http://arunponnusamy.com/files/mmod_human_face_detector.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_face_detector = dlib.cnn_face_detection_model_v1(\"./mmod_human_face_detector.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_cnn_test(path):\n",
    "    count = 1\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces_cnn = cnn_face_detector(gray, 1)\n",
    "    sets = path.split(\"/\")[2].split(\".\")\n",
    "    for face in faces_cnn:\n",
    "        x = face.rect.left()\n",
    "        y = face.rect.top()\n",
    "        w = face.rect.right() - x\n",
    "        h = face.rect.bottom() - y\n",
    "        try:\n",
    "            faceOrig = imutils.resize(img[y : y+h, x : x+w], width=200)\n",
    "            orig_name = \"./face_cnn_test/\" + sets[0] + \"_\" + str(count) +  \"_\" + \".\" +sets[1]\n",
    "            cv2.imwrite(orig_name, faceOrig)\n",
    "            count += 1\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    detect_cnn_test(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./face_cnn_test/\"\n",
    "files = os.listdir(data_path)\n",
    "\n",
    "n = 0\n",
    "for i in files:\n",
    "    oldname = data_path + files[n]\n",
    "    newname = data_path + files[n].split(\"_\")[0] + \".png\"\n",
    "    os.rename(oldname, newname)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path1 = \"./face_cnn_test/\"\n",
    "files1 = os.listdir(data_path1)\n",
    "\n",
    "data_path2 = \"./testing_set/\"\n",
    "files2 = os.listdir(data_path2)\n",
    "\n",
    "diff = []\n",
    "for i in files2:\n",
    "    if i not in files1:\n",
    "        diff.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_cnn_train(path):\n",
    "    count = 1\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces_cnn = cnn_face_detector(gray, 1)\n",
    "    sets1 = path.split(\"/\")\n",
    "    sets2 = path.split(\"/\")[3].split(\".\")\n",
    "    for face in faces_cnn:\n",
    "        x = face.rect.left()\n",
    "        y = face.rect.top()\n",
    "        w = face.rect.right() - x\n",
    "        h = face.rect.bottom() - y\n",
    "        try:\n",
    "            faceOrig = imutils.resize(img[y : y+h, x : x+w], width=200)\n",
    "            orig_name = \"./face_cnn_train/\" + sets1[2] + \"/\" + sets2[0] + \"_\" + str(count) +  \"_\" + \".\" +sets2[1]\n",
    "            cv2.imwrite(orig_name, faceOrig)\n",
    "            count += 1\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in x_data_list:\n",
    "    detect_cnn_train(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
